{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-03T22:41:21.563706Z",
     "start_time": "2025-09-03T22:41:21.549685Z"
    }
   },
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import functions\n",
    "import importlib\n",
    "importlib.reload(functions)\n",
    "import os\n",
    "from collections import deque\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T22:41:21.609501Z",
     "start_time": "2025-09-03T22:41:21.594851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "window_length = 10\n",
    "allAngles = []\n",
    "allPoints = []\n",
    "\n",
    "#Set up different Joints. The value at index 1 is the middle of the joint\n",
    "JOINTS_TO_TRACK = {\n",
    "    \"left_elbow\": [mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW, mp_pose.PoseLandmark.LEFT_WRIST],\n",
    "    \"right_elbow\": [mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW, mp_pose.PoseLandmark.RIGHT_WRIST],\n",
    "    \"left_knee\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_ANKLE],\n",
    "    \"right_knee\": [mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_ANKLE],\n",
    "    \"right_hip\": [mp_pose.PoseLandmark.RIGHT_KNEE, mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "    \"left_hip\": [mp_pose.PoseLandmark.LEFT_KNEE, mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "    \"left_shoulder\": [mp_pose.PoseLandmark.LEFT_HIP, mp_pose.PoseLandmark.LEFT_SHOULDER, mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "    \"right_shoulder\": [mp_pose.PoseLandmark.RIGHT_HIP, mp_pose.PoseLandmark.RIGHT_SHOULDER, mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "}\n",
    "\n",
    "#initializes a map to store the x,y,z coordinate of each body part at each frame\n",
    "landmark_positions = {}\n",
    "for position in mp_pose.PoseLandmark:\n",
    "    landmark_positions[position.value] = [[],[],[]]\n",
    "\n",
    "#Stores the angles calculated at each frame in a different map\n",
    "angle_history = {joint: [] for joint in JOINTS_TO_TRACK}\n",
    "\n",
    "script_dir = os.path.dirname(os.path.abspath(\"../ML Model and Testing/RecordSelf.ipynb\"))"
   ],
   "id": "d0c75edea7a9d16",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T22:41:49.721757Z",
     "start_time": "2025-09-03T22:41:21.633467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "    #Store Angle History\n",
    "    angle_windows = {}\n",
    "\n",
    "    for joint_name in JOINTS_TO_TRACK.keys():\n",
    "        # INIT DEQUES TO TAKE THE AVERAGE OF DATA IN A \"SLIDING WINDOW\"\n",
    "        # THIS HELPS TO SMOOTH THE DATA. Adjust Window Length to set smoothness\n",
    "        # of data\n",
    "        angle_windows[joint_name] = deque([], maxlen=window_length)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        #Detect if video loop is over and update data\n",
    "        '''if not ret:\n",
    "            points = {f\"landmark_{k}\": np.array(v) for k, v in landmark_positions.items()}\n",
    "            angles = {k: np.array(v) for k, v in angle_history.items()}\n",
    "            functions.save_lift_data(\"recordSelf\", points, angles, filename_tag=\"recordSelf\")'''\n",
    "\n",
    "\n",
    "        #Recolor the frame to RGB\n",
    "        image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "\n",
    "        #Recolor the frame back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            #EXTRACT LANDMARKS AND APPEND X,Y,Z COORDS TO LANDMARK_POSITIONS\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            for position in mp_pose.PoseLandmark:\n",
    "                landmark = landmarks[position.value]\n",
    "                landmark_positions[position.value][0].append(round(landmark.x,2))\n",
    "                landmark_positions[position.value][1].append(round(landmark.y,2))\n",
    "                landmark_positions[position.value][2].append(round(landmark.z,2))\n",
    "\n",
    "            #GO THRU EACH JOINT GIVEN IN JOINTS_TO_TRACK\n",
    "            for joint_name, landmark_indices in JOINTS_TO_TRACK.items():\n",
    "\n",
    "                try: #EXECUTE IF JOINT HAS ACTIVE DATAq\n",
    "                    a = landmarks[landmark_indices[0].value]\n",
    "                    b = landmarks[landmark_indices[1].value]\n",
    "                    c = landmarks[landmark_indices[2].value]\n",
    "\n",
    "                    # Use only x, y for 2D analysis\n",
    "                    angle = functions.calculate_angle(\n",
    "                        [a.x, a.y, a.z],\n",
    "                        [b.x, b.y, b.z],\n",
    "                        [c.x, c.y, c.z]\n",
    "                    )\n",
    "\n",
    "                    # ADD CURRENT ANGLE AT FRAME TO ANGLE_WINDOWS. IF ANGLE_WINDOWS IS AS LONG AS THE DEQUE EARLIER,\n",
    "                    # TAKE THE MEAN OF THE DEQUE. DEQUE IS UPDATED AT EACH FRAME, WITH THE FIRST VALUE IN THE DEQUE\n",
    "                    # BEING REMOVED AS THE LAST IS ADDED (FIFO DATA STRUCTURE)\n",
    "                    angle_windows[joint_name].append(angle)\n",
    "                    if len(angle_windows[joint_name]) == window_length:\n",
    "                        rolling_avg = np.mean(angle_windows[joint_name])\n",
    "                        angle_history[joint_name].append(int(rolling_avg))\n",
    "\n",
    "                    #ADD COORDINATES TO VIDEO\n",
    "                    x = a.x * cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "                    y = a.y * cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "                    cv2.putText(image, f\"{str(round(x ,2))}  {str(round(y,2))} {str(round(a.z,2))}\",\n",
    "                        np.multiply([a.x, a.y-.02], [cap.get(cv2.CAP_PROP_FRAME_WIDTH),cap.get(cv2.CAP_PROP_FRAME_HEIGHT)]).astype(int), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "                #IF LANDMARK IS NOT FOUND IN FOOTAGE, SET ANGLE TO NOT A NUMBER\n",
    "                except Exception:\n",
    "                    angle = np.nan\n",
    "\n",
    "                #IF WE HAVE AN ACTIVE ANGLE, DISPLAY THE ANGLE ON SCREEN\n",
    "                '''if not np.isnan(angle):\n",
    "                    b_coords = np.multiply([b.x, b.y], [image.shape[1], image.shape[0]]).astype(int)\n",
    "                    cv2.putText(\n",
    "                        image,\n",
    "                        f\"{joint_name}: {int(angle)}\",\n",
    "                        tuple(b_coords),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (255,255,255),\n",
    "                        2,\n",
    "                        cv2.LINE_AA\n",
    "                    )'''\n",
    "        #IF WE CANNOT EXTRACT LANDMARKS, JUST PASS\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #DRAW LANDMARKS AND CONNECTIONS IN VIDEO\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "        cv2.imshow('Mediapipe Feed',image)\n",
    "\n",
    "        #IF USER PRESSES Q, EXIT\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            print(\"User requested exit.\")\n",
    "            points = {f\"landmark_{k}\": np.array(v) for k, v in landmark_positions.items()}\n",
    "            angles = {k: np.array(v) for k, v in angle_history.items()}\n",
    "\n",
    "            functions.save_lift_data(\"recordSelf\", points, angles, filename_tag=\"recordSelf\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "a320e38893aa6053",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 28\u001B[39m\n\u001B[32m     25\u001B[39m image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n\u001B[32m     26\u001B[39m image.flags.writeable = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m28\u001B[39m results = \u001B[43mpose\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[38;5;66;03m#Recolor the frame back to BGR\u001B[39;00m\n\u001B[32m     31\u001B[39m image.flags.writeable = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\SeniorProject\\.venv\\Lib\\site-packages\\mediapipe\\python\\solutions\\pose.py:185\u001B[39m, in \u001B[36mPose.process\u001B[39m\u001B[34m(self, image)\u001B[39m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprocess\u001B[39m(\u001B[38;5;28mself\u001B[39m, image: np.ndarray) -> NamedTuple:\n\u001B[32m    165\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Processes an RGB image and returns the pose landmarks on the most prominent person detected.\u001B[39;00m\n\u001B[32m    166\u001B[39m \n\u001B[32m    167\u001B[39m \u001B[33;03m  Args:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    182\u001B[39m \u001B[33;03m         \"enable_segmentation\" is set to true.\u001B[39;00m\n\u001B[32m    183\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m185\u001B[39m   results = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_data\u001B[49m\u001B[43m=\u001B[49m\u001B[43m{\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mimage\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    186\u001B[39m   \u001B[38;5;28;01mif\u001B[39;00m results.pose_landmarks:  \u001B[38;5;66;03m# pytype: disable=attribute-error\u001B[39;00m\n\u001B[32m    187\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m landmark \u001B[38;5;129;01min\u001B[39;00m results.pose_landmarks.landmark:  \u001B[38;5;66;03m# pytype: disable=attribute-error\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\SeniorProject\\.venv\\Lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001B[39m, in \u001B[36mSolutionBase.process\u001B[39m\u001B[34m(self, input_data)\u001B[39m\n\u001B[32m    334\u001B[39m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    335\u001B[39m     \u001B[38;5;28mself\u001B[39m._graph.add_packet_to_input_stream(\n\u001B[32m    336\u001B[39m         stream=stream_name,\n\u001B[32m    337\u001B[39m         packet=\u001B[38;5;28mself\u001B[39m._make_packet(input_stream_type,\n\u001B[32m    338\u001B[39m                                  data).at(\u001B[38;5;28mself\u001B[39m._simulated_timestamp))\n\u001B[32m--> \u001B[39m\u001B[32m340\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_graph\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwait_until_idle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    341\u001B[39m \u001B[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001B[39;00m\n\u001B[32m    342\u001B[39m \u001B[38;5;66;03m# output stream names.\u001B[39;00m\n\u001B[32m    343\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._output_stream_type_info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T22:41:49.813127500Z",
     "start_time": "2025-08-27T17:40:36.790358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#NPZ VIEWING\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_dir = os.path.join(script_dir, '..', 'testing data')\n",
    "data = np.load(f\"{data_dir}\\\\recordSelf files\\\\recordSelf angles.npz\")\n",
    "\n",
    "\n",
    "for key in data:\n",
    "    joint_data = data[key]\n",
    "    print(f\"{key}: shape = {joint_data.shape}\")\n",
    "    plt.plot(joint_data, label=key)\n",
    "    plt.title(f\"{key} over time\")\n",
    "    plt.xlabel(\"Frame\")\n",
    "    plt.xlim(0,joint_data.shape[0])\n",
    "    plt.ylim(0,180)\n",
    "    plt.ylabel(\"Angle\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "56fe24f5b544cfaa",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Alex\\\\PycharmProjects\\\\SeniorProject\\\\ML Model and Testing\\\\..\\\\testing data\\\\recordSelf files\\\\recordSelf angles.npz'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mmatplotlib\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpyplot\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mplt\u001B[39;00m\n\u001B[32m      5\u001B[39m data_dir = os.path.join(script_dir, \u001B[33m'\u001B[39m\u001B[33m..\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mtesting data\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m data = \u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mdata_dir\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[33;43mrecordSelf files\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[33;43mrecordSelf angles.npz\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m data:\n\u001B[32m     10\u001B[39m     joint_data = data[key]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\SeniorProject\\.venv\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[39m\n\u001B[32m    425\u001B[39m     own_fid = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    426\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m427\u001B[39m     fid = stack.enter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[32m    428\u001B[39m     own_fid = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    430\u001B[39m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Alex\\\\PycharmProjects\\\\SeniorProject\\\\ML Model and Testing\\\\..\\\\testing data\\\\recordSelf files\\\\recordSelf angles.npz'"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
